---
title: "IE582 HW_2"
author: "Abdulsamed Kağıt"
date: "08/12/2020"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

## Task 1 

Read the data and visualize one instance (all axes) from each class and try to relate the shape (time series) you see with the gestures shown in Figure 1. 
A 3D scatter plot would be interesting. Note that this is an acceleration information. You can transform this information to a velocity vector by computing the cumulative sum of acceleration over time.

```{r Data Reading, echo=TRUE, message=FALSE, warning=FALSE}
#Libraries

library(ggplot2)
library(dplyr)
library(yardstick)
library(broom)
library(purrr)
library(data.table)
library(stringr)
library(tidyr)
library(ggfortify)
library(tidyverse)
library(plot3D)

#Data Reading

train_x <- fread("C:/Users/Abdulsamed/Desktop/IE582/uWaveGestureLibrary_X_TRAIN")
train_y <- fread("C:/Users/Abdulsamed/Desktop/IE582/uWaveGestureLibrary_Y_TRAIN")
train_z <- fread("C:/Users/Abdulsamed/Desktop/IE582/uWaveGestureLibrary_Z_TRAIN")

#Adjust Column Names

colnames(train_x)[1] = "class"
newnames <- paste("t",1: (ncol(train_x)-1), sep = "")
colnames(train_x)[2:ncol(train_x)] = newnames

colnames(train_y)[1] = "class"
newnames <- paste("t",1: (ncol(train_y)-1), sep = "")
colnames(train_y)[2:ncol(train_y)] = newnames

colnames(train_z)[1] = "class"
newnames <- paste("t",1: (ncol(train_z)-1), sep = "")
colnames(train_z)[2:ncol(train_z)] = newnames

#Calculate Velocity From Acceleration

mySum = t(apply(train_x[,-1], 1, cumsum))
train_x_velo <- cbind(train_x[,1],mySum)

mySum = t(apply(train_y[,-1], 1, cumsum))
train_y_velo <- cbind(train_y[,1],mySum)

mySum = t(apply(train_z[,-1], 1, cumsum))
train_z_velo <- cbind(train_z[,1],mySum)

#Calculate Position From Velocity

mySum = t(apply(train_x_velo[,-1], 1, cumsum))
train_x_pos <- cbind(train_x_velo[,1],mySum)

mySum = t(apply(train_y_velo[,-1], 1, cumsum))
train_y_pos <- cbind(train_y_velo[,1],mySum)

mySum = t(apply(train_z_velo[,-1], 1, cumsum))
train_z_pos <- cbind(train_z_velo[,1],mySum)

rm(mySum)

#Data Visualization

instances <- list()
for(i in 1:8)
{
instances=append(instances,list(cbind(t((train_x_pos%>%filter(class==i))[1,-1]),t((train_y_pos%>%filter(class==i))[1,-1]),t((train_z_pos%>%filter(class==i))[1,-1]))))
}


for(i in 1:8)
{
  a <- as.data.frame(unlist(instances[[i]]))
  scatter3D(x=a$V1,y=a$V2,z=a$V3, main=paste("An Instance From Class ", i))
  rm(a)
  }

```

3D scatter plots resemble the figures provided in the description.


## Task 2

The data is provided as a regular data matrix (i.e. each row represents an instance and columns represent the time index of the observations). On the other 
hand, this is an example of multivariate time series where we have X, Y and Z variables. Our aim is to reduce this multivariate time series to a univariate 
one with a dimensionality reduction approach. One way to achieve this task is to transform your data into the long format. Suppose we decide to reduce the 
data from 3D (i.e. X, Y and Z features) to 1D using PCA. Relevant columns for PCA is X, Y and Z. Apply PCA to the whole data (regardless of the time series 
id or class) and report PCA results. Select 2 random time series from each class and visualize the reduced dimensions as time series in a single plot to see 
if classes can be separated in the reduced dimensions. Visual inspection is enough.

```{r Longer Format, echo=TRUE, message=FALSE, warning=FALSE}
#Transform to Longer Format

train_x_adj <- cbind(time_series_id=1:nrow(train_x), train_x)
train_y_adj <- cbind(time_series_id=1:nrow(train_y), train_y)
train_z_adj <- cbind(time_series_id=1:nrow(train_z), train_z)

train_x_adj_long<-pivot_longer(train_x_adj,-contains("s"),names_to="time_index",values_to="x",names_prefix ="t",names_transform=list("time_index"=as.integer)) 
train_y_adj_long<-pivot_longer(train_y_adj,-contains("s"),names_to="time_index",values_to="y",names_prefix ="t",names_transform=list("time_index"=as.integer))
train_z_adj_long<-pivot_longer(train_z_adj,-contains("s"),names_to="time_index",values_to="z",names_prefix ="t",names_transform=list("time_index"=as.integer))

train_xyz_long <- inner_join(train_x_adj_long,train_y_adj_long,by=c("time_series_id","class","time_index"))
train_xyz_long <- inner_join(train_xyz_long,train_z_adj_long,by=c("time_series_id","class","time_index"))
train_xyz_long
```


```{r PCA, message=FALSE, warning=FALSE }
#PCA

pca_xyz <- prcomp(train_xyz_long%>%select(x,y,z), scale=TRUE)
tidy(pca_xyz,"pcs") #0.49 of the variance kept
pca_xyz$rotation

train_xyz_long_pca <- cbind(train_xyz_long,score=(pca_xyz$x)[,1]) %>% select(-x,-y,-z)

for(i in 1:8)
{
  chosen <- train_xyz_long_pca %>% filter(class == i)
  chosen <- unique(chosen$time_series_id) %>% sample(size=2)
  chosen1 <- train_xyz_long_pca %>% filter(time_series_id == chosen[1])
  chosen2 <- train_xyz_long_pca %>% filter(time_series_id == chosen[2])
  chosen <- bind_rows(chosen1,chosen2)
  chosen$time_series_id = as.character(chosen$time_series_id)
  print(ggplot(chosen,aes(x=time_index,y=score,color=time_series_id))+geom_line()+labs(title=paste("2 Randomly Picked Sample From Class ",i),x="Time Index",y="PCA Score"))
  rm(chosen,chosen1,chosen2)
  }

```

49% of the variance is explained by PC1. PC1 = c(x=0.4268455, y=0.7212650, z=0.5455087). 2 instances are sampled from each class and concluded that samples from same classes generally resemble each other. However it may not be possible to differentiate classes judging by PC1 only. Class 4 and Class 5 are good 
examples for that. Red line in the Class 4 graph (time_series_id = 550) are very similar to blue line in the Class 5 graph (time_series_id = 145) but they
are from different classes. 

## Task 3

It is also interesting to compare the first principal component when PCA is applied on the data from each gesture. In other words, you are expected to
filter the data for each class and apply PCA (you will perform PCA eight times). Report PCA results (components, variance covered by each component). Is 
there any  interesting observation on the first component of the PCA results applied to the data from each class? Are the first components similar? Comment 
on your findings.


```{r Class-Based PCA, message=FALSE, warning=FALSE}
#PCA for each class

class_pca <- train_xyz_long %>% group_by(class) %>% arrange(class) %>% nest() %>% 
 mutate(pca=purrr::map(data,function(d) prcomp(d%>%select(x,y,z))), rotation_pca= purrr::map(pca,function(d) tidy(d,matrix="rotation")%>%filter(PC==1)), 
    eigenvalues_pca = purrr::map(pca, function(d) tidy(d,matrix="eigenvalues")%>%filter(PC==1) %>% select(-PC))) %>% 
      unnest(c(rotation_pca,eigenvalues_pca)) %>% select(class,column, value, cumulative,PC) %>% pivot_wider(names_from = column, values_from=value)

class_pca
```

PCA results for each class are available in the data frame above. Negative PC1 of class 1 is similar to PC1 of class 2-5-7. PC1 of class 3 and 
class 4 are more or less similar as well. PC1 of class 2 and class 8 are similar to each other's negative. PC1 of Class 6 seems to be unique.

## Task 4

Suppose, our aim now is to visualize the time series in reduced dimensions for classification purposes. Assume that we compute the distance between 
the time series for each axis using the original representation (i.e. a row represents individual time series, column is the time index and entries 
are the observations) over each axis and sum them up to obtain a final distance measure. You are expected to obtain a symmetric distance matrix. 
Let’s apply multidimensional scaling to this distance matrix to represent each time series on a 2-dimensional feature space. Visualize the observations
using the reduced features and color-code the points with the class information. Comment on your findings.


```{r MDS, message=FALSE, warning=FALSE}
#MDS

mds_matris<- inner_join(train_x_adj,train_y_adj,by=c("class","time_series_id"),suffix=c("_x","_y"))
mds_matris<- inner_join(mds_matris,train_z_adj,by=c("class","time_series_id"))

distance_matrix <- dist(mds_matris%>%select(-class,-time_series_id))

mds_fit <- cmdscale(distance_matrix,eig=TRUE, k=2)

x <- mds_fit$points[,1]
y <- mds_fit$points[,2]

mds_applied_ts <- cbind(x,y,mds_matris[,1:2])
mds_applied_ts$class = as.character(mds_applied_ts$class)
mycolor <- c("#999999", "#E69F00", "#56B4E9", "#009E73","#F0E442", "#0072B2", "#D55E00", "#CC79A7")

ggplot(mds_applied_ts,aes(x=x,y=y,color=class))+geom_point() + scale_color_manual(values=mycolor) + 
  labs(title = "MDS with 2 dimensions",x="Coordinate 1", y="Coordinate 2")
```

Observations from same classes are tend to cluster mostly. It can be seen that class 2 and class 7, class 7 and class 8, class 4 and class 5 are 
kind of adjacent. Class 3 is wide-spread. Class 1 and Class 6 seems to be intertwined.

